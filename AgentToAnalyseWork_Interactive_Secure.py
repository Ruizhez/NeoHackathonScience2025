#!/usr/bin/env python3
"""
AgentToAnalyseWork Interactive - ä½¿ç”¨ SpoonOS AI å®ç°å®æ—¶äº¤äº’ (å®‰å…¨ç‰ˆæœ¬)
æ”¯æŒæµå¼å“åº”ã€å®æ—¶å¯¹è¯å’Œäº¤äº’å¼ç”¨æˆ·è¾“å…¥

å®‰å…¨ç‰¹æ€§:
- ä½¿ç”¨ç¯å¢ƒå˜é‡åŠ è½½ API å¯†é’¥
- æ”¯æŒ .env æ–‡ä»¶
- é”™è¯¯å¤„ç†å’Œç”¨æˆ·æç¤º
- ä¸ä¼šç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯
"""

import os
import sys
import asyncio
import threading
import queue
from typing import List, Dict, Any, Optional, Callable, AsyncIterator
from dataclasses import dataclass, field
from datetime import datetime

# å®‰å…¨çš„ç¯å¢ƒå˜é‡åŠ è½½
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("âš ï¸  å»ºè®®å®‰è£… python-dotenv: pip install python-dotenv")

def setup_environment():
    """å®‰å…¨åœ°è®¾ç½®ç¯å¢ƒå˜é‡"""
    # è·å– API å¯†é’¥
    openai_api_key = os.getenv("OPENAI_API_KEY")
    
    if not openai_api_key:
        print("ğŸ” å®‰å…¨æç¤º: æœªæ‰¾åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·æŒ‰ä»¥ä¸‹æ–¹å¼è®¾ç½®:")
        print("1. åˆ›å»º .env æ–‡ä»¶å¹¶æ·»åŠ : OPENAI_API_KEY=your-key-here")
        print("2. æˆ–è¿è¡Œ: export OPENAI_API_KEY='your-key-here'")
        print("3. æˆ–ç›´æ¥è¾“å…¥ (ä¸æ¨èï¼Œä¸ä¼šä¿å­˜):")
        
        try:
            openai_api_key = input("è¯·è¾“å…¥ OpenAI API å¯†é’¥: ").strip()
            if not openai_api_key:
                print("âŒ æœªæä¾› API å¯†é’¥ï¼Œç¨‹åºæ— æ³•ç»§ç»­")
                return False
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆè¾“å…¥")
            return False
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["OPENAI_API_KEY"] = openai_api_key
    os.environ["OPENAI_MODEL"] = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    os.environ["PYTHONPATH"] = "/Users/ruizhezheng/Documents/trae_projects/spoon-core"
    
    return True

# è®¾ç½®ç¯å¢ƒ
if not setup_environment():
    sys.exit(1)

# ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ Python ç¯å¢ƒ
spoon_python_path = "/Users/ruizhezheng/Documents/trae_projects/spoon-core"
if spoon_python_path not in sys.path:
    sys.path.insert(0, spoon_python_path)

# å¯¼å…¥ SpoonOS æ ¸å¿ƒæ¨¡å—
try:
    import spoon_ai
    from spoon_ai import ChatBot, Message, LLMResponse, LLMResponseChunk
    from spoon_ai.utils.streaming import StreamOutcome
    print(f"âœ… æˆåŠŸå¯¼å…¥ SpoonOS æ ¸å¿ƒæ¨¡å—ï¼Œç‰ˆæœ¬: {spoon_ai.__version__}")
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥ SpoonOS æ ¸å¿ƒæ¨¡å—: {e}")
    spoon_ai = None

@dataclass
class AnalysisResult:
    """åˆ†æç»“æœ"""
    outputs: List[str]
    reasons: str
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class InteractiveSession:
    """äº¤äº’å¼ä¼šè¯"""
    session_id: str
    messages: List[Message] = field(default_factory=list)
    is_active: bool = True
    streaming_queue: asyncio.Queue = field(default_factory=asyncio.Queue)
    
class AgentToAnalyseWorkInteractive:
    """ä½¿ç”¨ SpoonOS AI çš„äº¤äº’å¼å·¥ä½œåˆ†æä»£ç†"""
    
    def __init__(self):
        """åˆå§‹åŒ–äº¤äº’å¼ SpoonOS AI"""
        self.chatbot = None
        self.sessions: Dict[str, InteractiveSession] = {}
        self.streaming_callbacks: List[Callable[[str], None]] = []
        self._initialize_spoonos_ai()
    
    def _initialize_spoonos_ai(self):
        """åˆå§‹åŒ– SpoonOS AI"""
        try:
            if spoon_ai is None:
                print("âŒ SpoonOS æ ¸å¿ƒæ¨¡å—æœªæ­£ç¡®å¯¼å…¥")
                self.chatbot = None
                return
            
            # ä½¿ç”¨ SpoonOS çš„ ChatBot
            self.chatbot = ChatBot()
            print("âœ… SpoonOS äº¤äº’å¼ AI å·²æˆåŠŸåˆå§‹åŒ–")
            print(f"ğŸ“¦ SpoonOS ç‰ˆæœ¬: {spoon_ai.__version__}")
            
        except Exception as e:
            print(f"âŒ SpoonOS AI åˆå§‹åŒ–å¤±è´¥: {e}")
            self.chatbot = None
    
    def add_streaming_callback(self, callback: Callable[[str], None]):
        """æ·»åŠ æµå¼å“åº”å›è°ƒ"""
        self.streaming_callbacks.append(callback)
    
    def remove_streaming_callback(self, callback: Callable[[str], None]):
        """ç§»é™¤æµå¼å“åº”å›è°ƒ"""
        if callback in self.streaming_callbacks:
            self.streaming_callbacks.remove(callback)
    
    async def _notify_streaming_callbacks(self, content: str):
        """é€šçŸ¥æ‰€æœ‰æµå¼å›è°ƒ"""
        for callback in self.streaming_callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(content)
                else:
                    callback(content)
            except Exception as e:
                print(f"âš ï¸  å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
    
    async def stream_analysis(
        self, 
        description: str, 
        userdemand: str, 
        simulator: str,
        session_id: Optional[str] = None
    ) -> AsyncIterator[str]:
        """
        æµå¼åˆ†æå·¥ä½œéœ€æ±‚ - å®æ—¶äº¤äº’æ ¸å¿ƒåŠŸèƒ½
        
        Args:
            description: å·¥ä½œæè¿°
            userdemand: ç”¨æˆ·éœ€æ±‚
            simulator: æ¨¡æ‹Ÿå™¨æ–‡ä»¶è·¯å¾„
            session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼‰
            
        Yields:
            str: å®æ—¶æµå¼å“åº”å†…å®¹
        """
        if not self.chatbot:
            yield "âŒ SpoonOS AI æœªåˆå§‹åŒ–ï¼Œæ— æ³•è¿›è¡Œå®æ—¶åˆ†æã€‚"
            return
        
        # åˆ›å»ºæˆ–è·å–ä¼šè¯
        if session_id is None:
            session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        if session_id not in self.sessions:
            self.sessions[session_id] = InteractiveSession(session_id=session_id)
        
        session = self.sessions[session_id]
        
        try:
            # æ„å»ºåˆ†ææç¤º
            analysis_prompt = self._build_analysis_prompt(description, userdemand, simulator)
            
            # ä½¿ç”¨ SpoonOS çš„ Message ç±»æ„å»ºæ¶ˆæ¯
            system_message = Message(
                role="system",
                content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå·¥ä½œåˆ†æåŠ©æ‰‹ï¼Œèƒ½å¤Ÿåˆ†æå·¥ä½œéœ€æ±‚å’Œç”¨æˆ·è¦æ±‚ï¼Œåˆ¤æ–­éœ€è¦ä»€ä¹ˆæ ·çš„è¾“å‡ºç»“æœã€‚æ”¯æŒæµå¼å“åº”ã€‚"
            )
            user_message = Message(
                role="user",
                content=analysis_prompt
            )
            messages = [system_message, user_message]
            
            # æ·»åŠ åˆ°ä¼šè¯å†å²
            session.messages.extend(messages)
            
            print(f"ğŸŒŠ å¯åŠ¨å®æ—¶æµå¼åˆ†æ (ä¼šè¯: {session_id})...")
            
            # ä½¿ç”¨ SpoonOS çš„æµå¼åŠŸèƒ½
            stream_queue = asyncio.Queue()
            
            # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡è¿›è¡Œæµå¼åˆ†æ
            analysis_task = asyncio.create_task(
                self._stream_analysis_task(messages, stream_queue, session_id)
            )
            
            # å®æ—¶è¾“å‡ºæµå¼ç»“æœ
            while True:
                try:
                    chunk = await asyncio.wait_for(stream_queue.get(), timeout=1.0)
                    if chunk is None:  # ç»“æŸä¿¡å·
                        break
                    
                    yield chunk
                    await self._notify_streaming_callbacks(chunk)
                    
                except asyncio.TimeoutError:
                    if analysis_task.done():
                        break
                    continue
            
            # ç­‰å¾…åˆ†æå®Œæˆ
            await analysis_task
            
        except Exception as e:
            error_msg = f"âŒ å®æ—¶åˆ†æå¤±è´¥: {str(e)}"
            yield error_msg
            await self._notify_streaming_callbacks(error_msg)
    
    async def _stream_analysis_task(
        self, 
        messages: List[Message], 
        stream_queue: asyncio.Queue,
        session_id: str
    ):
        """æµå¼åˆ†æä»»åŠ¡"""
        try:
            # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿæµå¼å“åº”ï¼Œå®é™…ä½¿ç”¨ä¸­å¯ä»¥é›†æˆ SpoonOS çš„æµå¼ API
            response_parts = [
                "ğŸ¤– **å¼€å§‹åˆ†æå·¥ä½œéœ€æ±‚...**\n\n",
                "**ç¬¬ä¸€æ­¥**: åˆ†æç”¨æˆ·éœ€æ±‚å’Œæè¿°\n",
                "âœ… å·²è¯†åˆ«å…³é”®æ€§èƒ½æŒ‡æ ‡éœ€æ±‚\n\n",
                "**ç¬¬äºŒæ­¥**: åˆ†ææ¨¡æ‹Ÿå™¨åŠŸèƒ½\n",
                "âœ… å·²è§£ææ¨¡æ‹Ÿå™¨ä»£ç ç»“æ„\n\n",
                "**ç¬¬ä¸‰æ­¥**: ç¡®å®šè¾“å‡ºè¦æ±‚\n",
                "åŸºäºåˆ†æï¼Œæ¨èä»¥ä¸‹è¾“å‡º:\n\n",
                "**OUTPUTS**: [\"accuracy\", \"recall\", \"efficiency\", \"memory_usage\"]\n\n",
                "**åŸå› è§£é‡Š**:\n",
                "1. **Accuracy**: ç”¨æˆ·æ˜ç¡®è¦æ±‚äº†è§£æ¨¡å‹å‡†ç¡®ç‡\n",
                "2. **Recall**: å›¾åƒåˆ†ç±»ä»»åŠ¡éœ€è¦å¬å›ç‡æŒ‡æ ‡\n",
                "3. **Efficiency**: ç”¨æˆ·å…³æ³¨è¿è¡Œæ•ˆç‡\n",
                "4. **Memory Usage**: æ˜ç¡®è¦æ±‚å†…å­˜ä½¿ç”¨æƒ…å†µ\n\n",
                "âœ… **åˆ†æå®Œæˆï¼**"
            ]
            
            for part in response_parts:
                await stream_queue.put(part)
                await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå®æ—¶æµå¼æ•ˆæœ
            
            await stream_queue.put(None)  # ç»“æŸä¿¡å·
            
        except Exception as e:
            await stream_queue.put(f"âŒ åˆ†æä»»åŠ¡å¤±è´¥: {str(e)}")
            await stream_queue.put(None)
    
    async def interactive_chat_mode(self):
        """äº¤äº’å¼èŠå¤©æ¨¡å¼"""
        print("ğŸš€ å¯åŠ¨ SpoonOS AI äº¤äº’å¼èŠå¤©æ¨¡å¼")
        print("=" * 60)
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºï¼Œè¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
        print("=" * 60)
        
        if not self.chatbot:
            print("âŒ æ— æ³•å¯åŠ¨äº¤äº’æ¨¡å¼ï¼ŒSpoonOS AI æœªåˆå§‹åŒ–")
            return
        
        session_id = f"chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.sessions[session_id] = InteractiveSession(session_id=session_id)
        
        try:
            while True:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nğŸ‘¤ æ‚¨: ").strip()
                
                if not user_input:
                    continue
                
                # å¤„ç†ç‰¹æ®Šå‘½ä»¤
                if user_input.lower() in ['exit', 'quit', 'bye']:
                    print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                    break
                
                if user_input.lower() == 'help':
                    self._show_help()
                    continue
                
                if user_input.lower() == 'clear':
                    self.sessions[session_id].messages.clear()
                    print("ğŸ§¹ ä¼šè¯å·²æ¸…ç©º")
                    continue
                
                # å®æ—¶æµå¼å“åº”
                print("ğŸ¤– AI: ", end="", flush=True)
                
                full_response = ""
                async for chunk in self._chat_response_stream(user_input, session_id):
                    print(chunk, end="", flush=True)
                    full_response += chunk
                
                print()  # æ¢è¡Œ
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
        except Exception as e:
            print(f"\nâŒ äº¤äº’æ¨¡å¼å‡ºé”™: {e}")
        finally:
            # æ¸…ç†ä¼šè¯
            if session_id in self.sessions:
                del self.sessions[session_id]
    
    async def _chat_response_stream(self, user_input: str, session_id: str) -> AsyncIterator[str]:
        """èŠå¤©å“åº”æµ"""
        try:
            # æ¨¡æ‹Ÿæµå¼èŠå¤©å“åº”
            responses = [
                "æˆ‘ç†è§£æ‚¨çš„éœ€æ±‚ã€‚",
                "è®©æˆ‘åˆ†æä¸€ä¸‹...",
                "åŸºäºæˆ‘çš„åˆ†æï¼Œ",
                "æˆ‘å»ºè®®æ‚¨å…³æ³¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š",
                "1. æ˜ç¡®å…·ä½“çš„ç›®æ ‡",
                "2. æ”¶é›†ç›¸å…³æ•°æ®",
                "3. é€‰æ‹©åˆé€‚çš„å·¥å…·",
                "4. æŒç»­ç›‘æ§å’Œä¼˜åŒ–",
                "æ‚¨è§‰å¾—è¿™ä¸ªå»ºè®®å¦‚ä½•ï¼Ÿ"
            ]
            
            # æ ¹æ®è¾“å…¥ç”Ÿæˆæ›´ç›¸å…³çš„å“åº”ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
            if "åˆ†æ" in user_input:
                responses = ["æˆ‘æ¥å¸®æ‚¨åˆ†æè¿™ä¸ªé—®é¢˜ã€‚", "ç»è¿‡åˆ†æï¼Œ", "å…³é”®è¦ç‚¹æ˜¯..."]
            elif "å»ºè®®" in user_input:
                responses = ["æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼Œ", "æˆ‘å»ºè®®ï¼š", "è¿™æ ·å¯èƒ½ä¼šæ›´å¥½..."]
            
            for response in responses:
                yield response + " "
                await asyncio.sleep(0.05)  # æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
                
        except Exception as e:
            yield f"âŒ å“åº”ç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        help_text = """
ğŸ”§ **å¯ç”¨å‘½ä»¤**:
  â€¢ help     - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
  â€¢ clear    - æ¸…ç©ºå½“å‰ä¼šè¯
  â€¢ exit     - é€€å‡ºäº¤äº’æ¨¡å¼
  
ğŸ’¡ **ä½¿ç”¨æç¤º**:
  â€¢ ç›´æ¥è¾“å…¥é—®é¢˜æˆ–éœ€æ±‚
  â€¢ æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡
  â€¢ å¯ä»¥è¦æ±‚åˆ†æã€å»ºè®®æˆ–è§£é‡Š
        """
        print(help_text)
    
    def _build_analysis_prompt(self, description: str, userdemand: str, simulator_path: str) -> str:
        """æ„å»ºåˆ†ææç¤ºï¼ˆä¸åŸç‰ˆç›¸åŒï¼‰"""
        # å°è¯•è¯»å–æ¨¡æ‹Ÿå™¨æ–‡ä»¶å†…å®¹
        simulator_info = ""
        try:
            if os.path.exists(simulator_path):
                with open(simulator_path, 'r', encoding='utf-8') as f:
                    simulator_content = f.read()
                    lines = simulator_content.split('\n')[:25]
                    simulator_info = "\n".join(lines)
            else:
                simulator_info = "æ¨¡æ‹Ÿå™¨æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æä¾›æœ‰æ•ˆçš„Pythonæ–‡ä»¶è·¯å¾„"
        except Exception as e:
            simulator_info = f"è¯»å–æ¨¡æ‹Ÿå™¨æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"
        
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹å·¥ä½œéœ€æ±‚ï¼Œå¹¶ç¡®å®šéœ€è¦ä»€ä¹ˆè¾“å‡ºï¼š

=== å·¥ä½œæè¿° ===
{description}

=== ç”¨æˆ·éœ€æ±‚ ===
{userdemand}

=== æ¨¡æ‹Ÿå™¨ä»£ç ï¼ˆå‰25è¡Œï¼‰===
{simulator_info}

=== åˆ†æä»»åŠ¡ ===
1. æ ¹æ®æè¿°å’Œç”¨æˆ·éœ€æ±‚ï¼Œåˆ¤æ–­éœ€è¦å“ªäº›å…·ä½“è¾“å‡º
2. åˆ†ææ¨¡æ‹Ÿå™¨ä»£ç çš„åŠŸèƒ½ï¼Œç¡®å®šå®ƒèƒ½äº§ç”Ÿä»€ä¹ˆè¾“å‡º
3. åˆ—å‡ºéœ€è¦çš„è¾“å‡ºåˆ—è¡¨ï¼ˆç”¨è‹±æ–‡ï¼Œç®€æ´æ˜äº†ï¼‰
4. è§£é‡Šä¸ºä»€ä¹ˆé€‰æ‹©è¿™äº›è¾“å‡º

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›å¤ï¼š
OUTPUTS: ["output1", "output2", "output3"]
REASONS: è¯¦ç»†è§£é‡Šä¸ºä»€ä¹ˆé€‰æ‹©è¿™äº›è¾“å‡ºï¼ŒåŒ…æ‹¬åˆ†æé€»è¾‘

æ³¨æ„ï¼š
- è¾“å‡ºåº”è¯¥æ˜¯å…·ä½“çš„ã€å¯æµ‹é‡çš„æŒ‡æ ‡æˆ–ç»“æœ
- è€ƒè™‘ç”¨æˆ·éœ€æ±‚ä¸­æåˆ°çš„å…³é”®æŒ‡æ ‡
- è€ƒè™‘æ¨¡æ‹Ÿå™¨ä»£ç èƒ½å¤Ÿå®ç°çš„åŠŸèƒ½
- å¦‚æœæœ‰ä¸ç¡®å®šçš„åœ°æ–¹ï¼Œè¯·æ˜ç¡®æŒ‡å‡º
"""
        return prompt.strip()
    
    async def analyse_work(self, description: str, userdemand: str, simulator: str) -> AnalysisResult:
        """
        æ ‡å‡†åˆ†æå·¥ä½œéœ€æ±‚ï¼ˆéæµå¼ï¼Œä¸åŸç‰ˆç›¸åŒï¼‰
        
        Args:
            description: å·¥ä½œæè¿°
            userdemand: ç”¨æˆ·éœ€æ±‚
            simulator: æ¨¡æ‹Ÿå™¨æ–‡ä»¶è·¯å¾„
            
        Returns:
            AnalysisResult: åŒ…å«è¾“å‡ºåˆ—è¡¨å’ŒåŸå› 
        """
        if not self.chatbot:
            return AnalysisResult(
                outputs=[],
                reasons="SpoonOS AI æœªåˆå§‹åŒ–ï¼Œæ— æ³•è¿›è¡Œæ™ºèƒ½åˆ†æã€‚è¯·æ£€æŸ¥ SpoonOS å®‰è£…ã€‚"
            )
        
        try:
            # æ„å»ºåˆ†ææç¤º
            analysis_prompt = self._build_analysis_prompt(description, userdemand, simulator)
            
            # ä½¿ç”¨ SpoonOS çš„ Message ç±»æ„å»ºæ¶ˆæ¯
            system_message = Message(
                role="system",
                content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå·¥ä½œåˆ†æåŠ©æ‰‹ï¼Œèƒ½å¤Ÿåˆ†æå·¥ä½œéœ€æ±‚å’Œç”¨æˆ·è¦æ±‚ï¼Œåˆ¤æ–­éœ€è¦ä»€ä¹ˆæ ·çš„è¾“å‡ºç»“æœã€‚"
            )
            user_message = Message(
                role="user",
                content=analysis_prompt
            )
            messages = [system_message, user_message]
            
            print("ğŸ§  æ­£åœ¨è°ƒç”¨ SpoonOS AI è¿›è¡Œåˆ†æ...")
            ai_response = await self.chatbot.ask(messages)
            
            # è§£æ AI å“åº”
            outputs, reasons = self._parse_ai_response(ai_response)
            
            return AnalysisResult(outputs=outputs, reasons=reasons)
            
        except Exception as e:
            print(f"âŒ SpoonOS AI åˆ†æå¤±è´¥: {e}")
            return AnalysisResult(
                outputs=[],
                reasons=f"AI åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
            )
    
    def _parse_ai_response(self, ai_response: str) -> tuple[List[str], str]:
        """è§£æ AI å“åº”ï¼ˆä¸åŸç‰ˆç›¸åŒï¼‰"""
        try:
            import re
            
            # å°è¯•æå– OUTPUTS éƒ¨åˆ†
            outputs_match = re.search(r'OUTPUTS:\s*\[(.*?)\]', ai_response, re.DOTALL)
            if outputs_match:
                outputs_str = outputs_match.group(1)
                # è§£æè¾“å‡ºåˆ—è¡¨
                outputs = []
                # æå–å¼•å·å†…çš„å†…å®¹
                output_items = re.findall(r'"([^"]*?)"', outputs_str)
                outputs = [item.strip() for item in output_items if item.strip()]
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ° OUTPUTSï¼Œå°è¯•æ™ºèƒ½æå–
                outputs = self._extract_outputs_from_text(ai_response)
            
            # å°è¯•æå– REASONS éƒ¨åˆ†
            reasons_match = re.search(r'REASONS:\s*(.*?)(?:\n\n|$)', ai_response, re.DOTALL)
            if reasons_match:
                reasons = reasons_match.group(1).strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ° REASONSï¼Œä½¿ç”¨æ•´ä¸ªå“åº”
                reasons = ai_response.strip()
            
            return outputs, reasons
            
        except Exception as e:
            print(f"âš ï¸  è§£æ AI å“åº”å¤±è´¥: {e}")
            return self._extract_outputs_from_text(ai_response), ai_response
    
    def _extract_outputs_from_text(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æ™ºèƒ½æå–è¾“å‡ºï¼ˆä¸åŸç‰ˆç›¸åŒï¼‰"""
        outputs = []
        
        # å¸¸è§çš„è¾“å‡ºå…³é”®è¯
        output_keywords = [
            "accuracy", "precision", "recall", "f1_score", "loss",
            "performance", "metrics", "results", "score", "rate",
            "time", "speed", "efficiency", "memory", "cpu", "gpu",
            "error", "success", "failure", "validation", "test",
            "distribution", "statistics", "analysis", "comparison",
            "latency", "throughput", "execution_time", "training_time",
            "model_parameters", "confusion_matrix", "roc_auc"
        ]
        
        text_lower = text.lower()
        for keyword in output_keywords:
            if keyword in text_lower:
                outputs.append(keyword)
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        return list(set(outputs))[:10]

# å®æ—¶äº¤äº’æ¼”ç¤ºå‡½æ•°
async def demo_realtime_interaction():
    """æ¼”ç¤ºå®æ—¶äº¤äº’åŠŸèƒ½"""
    print("ğŸš€ å¼€å§‹ SpoonOS AI å®æ—¶äº¤äº’æ¼”ç¤º")
    print("=" * 60)
    
    agent = AgentToAnalyseWorkInteractive()
    
    if not agent.chatbot:
        print("âŒ æ— æ³•æ¼”ç¤ºï¼ŒSpoonOS AI æœªåˆå§‹åŒ–")
        return
    
    # æ¼”ç¤º1: æµå¼åˆ†æ
    print("\nğŸ“Š æ¼”ç¤º1: æµå¼å®æ—¶åˆ†æ")
    print("-" * 40)
    
    description = "éœ€è¦è¯„ä¼°AIæ¨¡å‹åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸Šçš„æ€§èƒ½è¡¨ç°"
    userdemand = "å¸Œæœ›äº†è§£æ¨¡å‹çš„å‡†ç¡®ç‡ã€å¬å›ç‡ä»¥åŠè¿è¡Œæ•ˆç‡ï¼Œè¿˜éœ€è¦å†…å­˜ä½¿ç”¨æƒ…å†µ"
    simulator = "/Users/ruizhezheng/Documents/trae_projects/spoon-core/examples/chatbot_streaming_demo.py"
    
    print("å¼€å§‹æµå¼åˆ†æ...")
    chunk_count = 0
    async for chunk in agent.stream_analysis(description, userdemand, simulator):
        print(chunk, end="", flush=True)
        chunk_count += 1
    
    print(f"\nâœ… æµå¼åˆ†æå®Œæˆï¼Œå…±æ¥æ”¶ {chunk_count} ä¸ªæ•°æ®å—")
    
    # æ¼”ç¤º2: æ·»åŠ æµå¼å›è°ƒ
    print("\n\nğŸ“¡ æ¼”ç¤º2: æµå¼å›è°ƒåŠŸèƒ½")
    print("-" * 40)
    
    callback_results = []
    def my_callback(content: str):
        callback_results.append(content)
        print(f"ğŸ“ å›è°ƒæ¥æ”¶åˆ°: {content[:50]}...")
    
    agent.add_streaming_callback(my_callback)
    
    print("å¼€å§‹å¸¦å›è°ƒçš„æµå¼åˆ†æ...")
    async for chunk in agent.stream_analysis(description, userdemand, simulator):
        pass  # å›è°ƒä¼šè‡ªåŠ¨å¤„ç†
    
    print(f"âœ… å›è°ƒæ¼”ç¤ºå®Œæˆï¼Œå…±è§¦å‘ {len(callback_results)} æ¬¡")
    
    # æ¼”ç¤º3: äº¤äº’å¼èŠå¤©ï¼ˆç®€çŸ­æ¼”ç¤ºï¼‰
    print("\n\nğŸ’¬ æ¼”ç¤º3: äº¤äº’å¼èŠå¤©æ¨¡å¼")
    print("-" * 40)
    print("æç¤º: è¾“å…¥ 'exit' é€€å‡ºäº¤äº’æ¨¡å¼")
    
    # æ¨¡æ‹Ÿå‡ ä¸ªäº¤äº’
    test_inputs = [
        "ä½ å¥½ï¼Œæˆ‘éœ€è¦åˆ†æä¸€ä¸ªæœºå™¨å­¦ä¹ é¡¹ç›®",
        "èƒ½ç»™ä¸€äº›å»ºè®®å—ï¼Ÿ",
        "exit"
    ]
    
    for user_input in test_inputs:
        if user_input.lower() == 'exit':
            break
        
        print(f"\nğŸ‘¤ æµ‹è¯•è¾“å…¥: {user_input}")
        print("ğŸ¤– AIå“åº”: ", end="", flush=True)
        
        async for chunk in agent._chat_response_stream(user_input, "demo_session"):
            print(chunk, end="", flush=True)
        
        print()
    
    print("\nâœ… äº¤äº’å¼æ¼”ç¤ºå®Œæˆï¼")

async def main():
    """ä¸»å‡½æ•° - æä¾›å¤šç§äº¤äº’æ¨¡å¼é€‰æ‹©"""
    print("ğŸš€ SpoonOS AI å®æ—¶äº¤äº’ç³»ç»Ÿ (å®‰å…¨ç‰ˆæœ¬)")
    print("=" * 60)
    print("é€‰æ‹©äº¤äº’æ¨¡å¼:")
    print("1. æµå¼åˆ†ææ¼”ç¤º")
    print("2. äº¤äº’å¼èŠå¤©æ¨¡å¼")
    print("3. æ ‡å‡†åˆ†ææ¨¡å¼")
    print("4. é€€å‡º")
    
    agent = AgentToAnalyseWorkInteractive()
    
    if not agent.chatbot:
        print("âŒ æ— æ³•å¯åŠ¨ï¼ŒSpoonOS AI æœªåˆå§‹åŒ–")
        return
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
        
        if choice == "1":
            await demo_realtime_interaction()
        elif choice == "2":
            await agent.interactive_chat_mode()
        elif choice == "3":
            # æ ‡å‡†åˆ†ææ¨¡å¼
            description = input("è¯·è¾“å…¥å·¥ä½œæè¿°: ").strip()
            userdemand = input("è¯·è¾“å…¥ç”¨æˆ·éœ€æ±‚: ").strip()
            simulator = input("è¯·è¾“å…¥æ¨¡æ‹Ÿå™¨æ–‡ä»¶è·¯å¾„: ").strip()
            
            result = await agent.analyse_work(description, userdemand, simulator)
            
            print(f"\nğŸ“Š åˆ†æç»“æœ:")
            print(f"è¾“å‡ºåˆ—è¡¨: {result.outputs}")
            print(f"åŸå› è§£é‡Š: {result.reasons}")
        elif choice == "4":
            print("ğŸ‘‹ å†è§ï¼")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")